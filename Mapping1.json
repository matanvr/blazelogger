{"mappingId":"Mapping111","applicationID":"application_1465412277317_3616","gridtaskID":"gtid-3616-1-40834268-20","sessionLog":"2016-07-12 14:06:08.404 <DTFPool-3-thread-50> INFO: [MPSVCCMN_10083] The Mapping Service Module submitted a job to the Integration Service.  Job ID : [dC9GBUh0EeaF2MsdhhUm-g]2016-07-12 14:06:08.408 <DTFPool-3-thread-50> INFO: [DS_10178] The job is running on Integration Service [DIS_CDH]. The Launch Job Options for the service is set to: [In separate local processes (OUT_OF_PROCESS)].2016-07-12 14:06:08.447 <DTFPool-3-thread-50> FINE: Translating SDK-based hadoop execution environment connection [CDH_psrhaqadn51].2016-07-12 14:06:08.448 <DTFPool-3-thread-50> INFO: [LDTM_0117] Choose mapping execution engine [Informatica engine on hadoop cluster].2016-07-12 14:06:08.466 <DTFPool-3-thread-50> INFO: [LDTM_0026] LDTM: Starting mapping compilation.2016-07-12 14:06:08.466 <DTFPool-3-thread-50> INFO: [LDTMPARAM_0013] The Integration Service uses the value [/data/home/dtmqa/Informatica/10.1.0/364/tomcat/bin/reject] for the system parameter [RejectDir].2016-07-12 14:06:08.466 <DTFPool-3-thread-50> INFO: [LDTMPARAM_0013] The Integration Service uses the value [/data/home/dtmqa/Informatica/10.1.0/364/tomcat/bin/stateStore] for the system parameter [StateStore].2016-07-12 14:06:08.466 <DTFPool-3-thread-50> INFO: [LDTMPARAM_0013] The Integration Service uses the value [/data/home/dtmqa/Informatica/10.1.0/364/tomcat/bin/cache] for the system parameter [CacheDir].2016-07-12 14:06:08.466 <DTFPool-3-thread-50> INFO: [LDTMPARAM_0013] The Integration Service uses the value [/data/home/dtmqa/Informatica/10.1.0/364/tomcat/bin/disTemp] for the system parameter [TempDir].2016-07-12 14:06:08.467 <DTFPool-3-thread-50> INFO: [LDTMPARAM_0013] The Integration Service uses the value [/data/home/dtmqa/Informatica/10.1.0/364/tomcat/bin/target] for the system parameter [TargetDir].2016-07-12 14:06:08.467 <DTFPool-3-thread-50> INFO: [LDTMPARAM_0013] The Integration Service uses the value [/data/home/dtmqa/Informatica/10.1.0/364/tomcat/bin/source] for the system parameter [SourceDir].2016-07-12 14:06:08.467 <DTFPool-3-thread-50> INFO: [LDTMPARAM_0013] The Integration Service uses the value [DIS_CDH] for the system parameter [ServiceName].2016-07-12 14:06:08.467 <DTFPool-3-thread-50> INFO: [LDTMPARAM_0013] The Integration Service uses the value [Preview] for the system parameter [ApplicationName].2016-07-12 14:06:08.467 <DTFPool-3-thread-50> INFO: [LDTMPARAM_0013] The Integration Service uses the value [Native\\Administrator] for the system parameter [UserName].2016-07-12 14:06:08.467 <DTFPool-3-thread-50> INFO: [LDTMPARAM_0013] The Integration Service uses the value [INFA456847] for the system parameter [MappingName].2016-07-12 14:06:08.467 <DTFPool-3-thread-50> INFO: [LDTMPARAM_0013] The Integration Service uses the value [07/12/2016 14:06:08] for the system parameter [MappingRunStartTime].2016-07-12 14:06:08.467 <DTFPool-3-thread-50> INFO: [LDTMPARAM_0013] The Integration Service uses the value [blaze-on-hadoop] for the system parameter [ExecutionEnvironment].2016-07-12 14:06:08.478 <DTFPool-3-thread-50> FINEST: Encountered Read_ALL_DATATYPES_SUCHARITHA2016-07-12 14:06:08.495 <DTFPool-3-thread-50> FINEST: Encountered Write_ADT_TGT2016-07-12 14:06:08.505 <DTFPool-3-thread-50> INFO: [LDTM_0027] LDTM: Mapping compilation done.2016-07-12 14:06:08.546 <DTFPool-3-thread-50> INFO: [LDTM_0035] LDTM: Starting mapping translation.2016-07-12 14:06:08.547 <DTFPool-3-thread-50> INFO: [LDTM_0036] LDTM: Mapping translation finished.2016-07-12 14:06:08.547 <DTFPool-3-thread-50> INFO: [LDTM_1202] LDTM: Starting mapping simplification.2016-07-12 14:06:08.551 <DTFPool-3-thread-50> INFO: [LDTM_1203] LDTM: Mapping simplification complete.2016-07-12 14:06:08.551 <DTFPool-3-thread-50> INFO: [LDTM_0028] LDTM: Optimizing mapping...2016-07-12 14:06:08.552 <DTFPool-3-thread-50> FINE: [OPT_0600] The optimizer will use the following configuration:Optimizer.IgnoreOrderOfOp: trueOptimizer.IgnoreOrderOfImplicitDataConv: trueDTM.DateFormat: MM/DD/YYYY HH24:MI:SSDTM.HighPrecisionEnabled: trueDTM.LookupParseOverride: falseOptimizer.TreatOutputFieldErrorAsSideEffect: falseDTM.TreatNullInComparisonOperatorsAs: NULLOptimizer.EnableEarlyUncorrelatedSubquery: falseOptimizer.EnablePredicateInference: falseOptimizer.EnablePredicateMinimization: falseOptimizer.EnableEarlyProjection: falseOptimizer.EnableEarlySelection: falseOptimizer.EnableSemiJoin: falseOptimizer.EnableDatashipJoin: falseOptimizer.EnableCostBasedOptimization: falseOptimizer.EnableBranchPruning: falseDTM.CommitType: targetisAsciiMode: falseReservedWordsFile: nullOptimizer.PdoEnabledToSources: falseOptimizer.PushdownType: none2016-07-12 14:06:08.552 <DTFPool-3-thread-50> FINE: Optimizer.GlobalPredicateOptimization: false2016-07-12 14:06:08.552 <DTFPool-3-thread-50> INFO: [OPT_1600] The Integration Service is extracting constraints from sources.2016-07-12 14:06:08.552 <DTFPool-3-thread-50> INFO: [OPT_1603] The Integration Service is extracting constraints from the source [Read_ALL_DATATYPES_SUCHARITHA].2016-07-12 14:06:12.322 <DTFPool-3-thread-50> FINE: [OPT_1614] The Integration Service did not extract any constraints for the source [Read_ALL_DATATYPES_SUCHARITHA].2016-07-12 14:06:12.322 <DTFPool-3-thread-50> INFO: [OPT_1601] The Integration Service has finished extracting constraints from sources.2016-07-12 14:06:12.322 <DTFPool-3-thread-50> INFO: [OPT_1300] Running expression simplifier.2016-07-12 14:06:12.322 <DTFPool-3-thread-50> INFO: [OPT_1702] Global Predicate Optimization is not enabled for this mapping.2016-07-12 14:06:12.322 <DTFPool-3-thread-50> INFO: [OPT_0502] Predicate optimization was skipped.2016-07-12 14:06:12.323 <DTFPool-3-thread-50> INFO: [OPT_1300] Running expression simplifier.2016-07-12 14:06:12.323 <DTFPool-3-thread-50> INFO: [OPT_1402] Branch pruning optimization is not enabled for this mapping.2016-07-12 14:06:12.323 <DTFPool-3-thread-50> INFO: [OPT_63306] Pushdown optimization is not enabled for this mapping.2016-07-12 14:06:12.323 <DTFPool-3-thread-50> INFO: [LDTM_0029] LDTM: Mapping optimization done.2016-07-12 14:06:12.323 <DTFPool-3-thread-50> INFO: [LDTM_0038] LDTM: Starting operations on data sources after optimization.2016-07-12 14:06:12.599 <DTFPool-3-thread-50> INFO: [LDTM_0039] LDTM: Post-optimization tasks for operations on data sources are complete.2016-07-12 14:06:22.098 <DTFPool-3-thread-50> WARNING: [OPT_68103] Cost-based optimization failed to fetch statistics and will use dummy statistics. Cardinality value is [-1].2016-07-12 14:06:22.101 <DTFPool-3-thread-50> INFO: Cardinality coefficient per partition: 100002016-07-12 14:06:22.101 <DTFPool-3-thread-50> INFO: AutoPartitionResult {    GlobalMaxPartitions: 1    TxPartitionInfo {        Instance: Read_ALL_DATATYPES_SUCHARITHA        MaxPartitions: 1        IdealMaxPartitions: 1        IsPartitionPoint: true        IsOnForcedPartitionPath: false        GroupOrdering: O        TxPartitionGroupInfo {            Interface: Group            DataPartitionScheme {                Interface: Group                PartitionScheme: ArbitraryPartitioning                MergeScheme: DefaultMerge            }            PartitioningPointScheme {                Interface: Group                PartitionScheme: RangePartitioning                PartitioningKeys {                    COL_KEY                }                MergeScheme: DefaultMerge            }            IsInput: true            MergeSPMLocator: NA            Ords: {}            ExtrapolatedRowCount: -1            ExtrapolatedVolume: 0        }        TxPartitionGroupInfo {            Interface: Group            DataPartitionScheme {                Interface: Group                PartitionScheme: ArbitraryPartitioning                MergeScheme: DefaultMerge            }            IsInput: false            MergeSPMLocator: NA            Ords: NA            ExtrapolatedRowCount: 10000            ExtrapolatedVolume: 211060000        }    }    TxPartitionInfo {        Instance: Write_ADT_TGT        MaxPartitions: 1        IdealMaxPartitions: 1        IsPartitionPoint: true        IsOnForcedPartitionPath: false        GroupOrdering: O        TxPartitionGroupInfo {            Interface: Group            DataPartitionScheme {                Interface: Group                PartitionScheme: ArbitraryPartitioning                MergeScheme: DefaultMerge            }            PartitioningPointScheme {                Interface: Group                PartitionScheme: ArbitraryPartitioning                MergeScheme: DefaultMerge            }            IsInput: true            MergeSPMLocator: NA            Ords: {            ExtrapolatedRowCount: 10000            ExtrapolatedVolume: 211060000        }    }}2016-07-12 14:06:22.101 <DTFPool-3-thread-50> INFO: Partitioning is enabled for the mapping.2016-07-12 14:06:22.101 <DTFPool-3-thread-50> INFO: [LDTM_1204] LDTM: Starting mapping simplification clean up.2016-07-12 14:06:22.103 <DTFPool-3-thread-50> INFO: [LDTM_1205] LDTM: Mapping simplification clean up complete.2016-07-12 14:06:22.103 <DTFPool-3-thread-50> INFO: [LDTM_0030] LDTM: Preparing to execute the mapping.2016-07-12 14:06:22.104 <DTFPool-3-thread-50> FINE: [LDTM_3511] The Integration Service has pushed transformation [Read_ALL_DATATYPES_SUCHARITHA] to the grid environment.2016-07-12 14:06:22.107 <DTFPool-3-thread-50> FINE: [LDTM_3511] The Integration Service has pushed transformation [Write_ADT_TGT] to the grid environment.2016-07-12 14:06:22.122 <DTFPool-3-thread-50> INFO: [LDTM_0030] LDTM: Preparing to execute the mapping.2016-07-12 14:06:22.122 <DTFPool-3-thread-50> INFO: [LDTM_0074] Total time to create the LDTM: 13,691 ms2016-07-12 14:06:22.126 <DTM-pool-2-thread-3> INFO: [LDTM_0099] Session [INFA456847] is running in process [59041] on platform [Linux] (architecture [amd64]), product version [10.1.0], build version [364], build date [2016/06/13].2016-07-12 14:06:22.134 <DTM-pool-2-thread-3> FINE: [LDTM_0100] Using configuration property [$PMTempDir,/data/home/dtmqa/Informatica/10.1.0/364/tomcat/bin/disTemp].2016-07-12 14:06:22.139 <pool-6-thread-8> INFO: [LDTM_3504] The Integration Service started running the [Command] task [PRESESSION_task0].2016-07-12 14:06:22.141 <pool-6-thread-8> FINE: [LDTM_0126] Command task: [PRESESSION_task0]. Command executing: [1/1]. Command string executing: [../../services/shared/hadoop/cloudera_cdh5u5/scripts/HadoopFsMkdir --hadoop.home ../../services/shared/hadoop/cloudera_cdh5u5 --hdfsUser dtmqa hdfs://psrhaqann51.informatica.com:8020//blaze/workdir/W7798867335968217259_Write_ADT_TGT_INFA456847/reject-files//].2016-07-12 14:06:24.097 <pool-6-thread-8> FINE: [LDTM_0127] Command task: [PRESESSION_task0]. Command executing: [1/1]. Command execution process: [STDOUT/STDERR]. Command execution output: [Directory creation successful.].2016-07-12 14:06:24.097 <pool-6-thread-8> INFO: [LDTM_0128] The Command task [PRESESSION_task0] has successfully completed [1/1] commands2016-07-12 14:06:24.097 <pool-6-thread-8> INFO: [LDTM_3505] The Integration Service finished running the task [PRESESSION_task0].2016-07-12 14:06:24.098 <pool-6-thread-8> INFO: [LDTM_3504] The Integration Service started running the [[LDTM_3508] Grid Mapping] task [MAINSESSION_task1].2016-07-12 14:06:24.098 <pool-6-thread-8> FINEST: Executing grid mapping task [MAINSESSION_task1] now ...2016-07-12 14:06:24.099 <pool-6-thread-8> FINE: [task MAINSESSION_task1]: Grid execution configuration property [infagrid.dis.informatica.home] comes from hadoop pushdown configuration.2016-07-12 14:06:24.099 <pool-6-thread-8> FINE: [task MAINSESSION_task1]: Grid execution configuration property [infagrid.dis.hadoop.dist] comes from hadoop pushdown configuration.2016-07-12 14:06:24.099 <pool-6-thread-8> FINE: [task MAINSESSION_task1]: Grid execution configuration property [infagrid.hadoop.node.informatica.home] comes from hadoop pushdown configuration.2016-07-12 14:06:24.099 <pool-6-thread-8> FINE: [task MAINSESSION_task1]: Grid execution configuration property [infagrid.hadoop.node.hadoop.dist] comes from hadoop pushdown configuration.2016-07-12 14:06:24.099 <pool-6-thread-8> FINE: [task MAINSESSION_task1]: Grid execution configuration property [infagrid.dis.hadoop.dir] comes from hadoop pushdown configuration.2016-07-12 14:06:24.099 <pool-6-thread-8> FINE: [task MAINSESSION_task1]: Grid execution configuration property [infacal.hadoop.env.entry.INFA_MAPRED_OSGI_CONFIG] comes from hadoop pushdown configuration.2016-07-12 14:06:24.099 <pool-6-thread-8> FINE: [task MAINSESSION_task1]: Grid execution configuration property [infacal.hadoop.env.entry.INFA_RESOURCES] comes from hadoop pushdown configuration.2016-07-12 14:06:24.099 <pool-6-thread-8> FINE: [task MAINSESSION_task1]: Grid execution configuration property [infacal.hadoop.env.entry.LD_LIBRARY_PATH] comes from hadoop pushdown configuration.2016-07-12 14:06:24.099 <pool-6-thread-8> FINE: [task MAINSESSION_task1]: Grid execution configuration property [infacal.hadoop.env.entry.INFA_JAVA_BIN] comes from hadoop pushdown configuration.2016-07-12 14:06:24.099 <pool-6-thread-8> FINE: [task MAINSESSION_task1]: Grid execution configuration property [infacal.hadoop.env.entry.INFA_MAPRED_CLASSPATH] comes from hadoop pushdown configuration.2016-07-12 14:06:24.099 <pool-6-thread-8> FINE: [task MAINSESSION_task1]: Grid execution configuration property [infacal.hadoop.env.entry.INFA_PLUGINS_HOME] comes from hadoop pushdown configuration.2016-07-12 14:06:24.099 <pool-6-thread-8> FINE: [task MAINSESSION_task1]: Grid execution configuration property [infacal.hadoop.env.entry.IFCONTENTMASTER_HOME] comes from hadoop pushdown configuration.2016-07-12 14:06:24.099 <pool-6-thread-8> FINE: [task MAINSESSION_task1]: Grid execution configuration property [infacal.hadoop.env.entry.IMF_CPP_RESOURCE_PATH] comes from hadoop pushdown configuration.2016-07-12 14:06:24.099 <pool-6-thread-8> FINE: [task MAINSESSION_task1]: Grid execution configuration property [infacal.hadoop.env.entry.INFA_HADOOP_DIST_DIR] comes from hadoop pushdown configuration.2016-07-12 14:06:24.099 <pool-6-thread-8> FINE: [task MAINSESSION_task1]: Grid execution configuration property [infacal.hadoop.env.entry.INFA_HOME] comes from hadoop pushdown configuration.2016-07-12 14:06:24.105 <pool-6-thread-8> INFO: [task MAINSESSION_task1]: [GRIDDTM_2056] Map-side rank is disabled.2016-07-12 14:06:24.106 <pool-6-thread-8> FINE: [task MAINSESSION_task1]: [GRIDDTM_1003] The Integration Service started updating the partitioning metadata of the grid mapping.2016-07-12 14:06:24.106 <pool-6-thread-8> FINE: [task MAINSESSION_task1]: [GRIDDTM_1004] The Integration Service finished updating the partitioning metadata of the grid mapping.2016-07-12 14:06:24.106 <pool-6-thread-8> FINE: [task MAINSESSION_task1]: [GRIDDTM_1005] The Integration Service started segmenting the grid mapping.2016-07-12 14:06:24.106 <pool-6-thread-8> INFO: [task MAINSESSION_task1]: [GRIDDTM_2058] Start executing partial reducing phase.2016-07-12 14:06:24.111 <pool-6-thread-8> FINE: [task MAINSESSION_task1]: Grid task : total 2 segments.   Segment [submapping-1]:      Included instances: Write_ADT_TGT(TargetTxImpl), Read_ALL_DATATYPES_SUCHARITHA(SourceTxImpl)      Number of tasklets: 1      Estimated major memory consumption: 654835712      Number of cores required for each tasklet: 1      Segments blocking me: sub-mapping-2_pretask_of_submapping-1[MANDATORY]   Segment [sub-mapping-2_pretask_of_submapping-1]:      Included instances: Write_ADT_TGT(TargetTxImpl), empty_source(SourceTxImpl)      Number of tasklets: 1      Estimated major memory consumption: 52428800      Number of cores required for each tasklet: 1      Segments blocked by me: submapping-1[MANDATORY]      Tasklet doesnt have partition info, this segment must be a grid-mapping subtask.2016-07-12 14:06:24.111 <pool-6-thread-8> FINE: [task MAINSESSION_task1]: [GRIDDTM_1006] The Integration Service finished segmenting the grid mapping.2016-07-12 14:06:24.111 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [infaspark.driver.client.mode.extraJavaOptions,-Djava.security.egd=file:/dev/./urandom -XX:MaxMetaspaceSize=256M].2016-07-12 14:06:24.111 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [infaspark.driver.cluster.mode.osgi.config,osgi.framework.activeThreadType:false&:org.osgi.framework.storage.clean:none&:eclipse.jobs.daemon:true&:infa.osgi.enable.workdir.reuse:true&:infa.osgi.parent.workdir:/tmp/infaSparkClusterDriver/&:infa.osgi.workdir.poolsize:4].2016-07-12 14:06:24.111 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [infagrid.blaze.console.jsfport,9090].2016-07-12 14:06:24.111 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [infagrid.hadoop.node.hadoop.dist,/opt/Informatica/services/shared/hadoop/cloudera_cdh5u5].2016-07-12 14:06:24.111 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [infagrid.service.port.range.low,12300].2016-07-12 14:06:24.111 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [infagrid.blaze.console.httpport,9080].2016-07-12 14:06:24.111 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [infaspark.executor.osgi.config,osgi.framework.activeThreadType:false&:org.osgi.framework.storage.clean:none&:eclipse.jobs.daemon:true&:infa.osgi.enable.workdir.reuse:true&:infa.osgi.parent.workdir:/tmp/infaSparkExecutor/&:infa.osgi.workdir.poolsize:10].2016-07-12 14:06:24.111 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [spark.executor.cores,2].2016-07-12 14:06:24.111 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [spark.shuffle.consolidateFiles,TRUE].2016-07-12 14:06:24.111 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [infaspark.driver.cluster.mode.thirdparty.jars,/opt/Informatica/services/shared/hadoop/cloudera_cdh5u5/lib/datanucleus-api-jdo-3.2.6.jar,/opt/Informatica/services/shared/hadoop/cloudera_cdh5u5/lib/datanucleus-core-3.2.10.jar,/opt/Informatica/services/shared/hadoop/cloudera_cdh5u5/lib/datanucleus-rdbms-3.2.9.jar,/opt/Informatica/services/shared/hadoop/cloudera_cdh5u5/infaLib/xml-infa-parserutil.jar,/opt/Informatica/services/shared/hadoop/cloudera_cdh5u5/infaLib/json-infa-parserutil.jar,/opt/Informatica/services/shared/hadoop/cloudera_cdh5u5/i...[Truncated]].2016-07-12 14:06:24.111 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [infagrid.node.local.root.log.dir,/opt/Informatica//blazeLogs].2016-07-12 14:06:24.111 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [infagrid.blaze.console.memory,1024].2016-07-12 14:06:24.111 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [infagrid.hadoop.node.informatica.home,/opt/Informatica/].2016-07-12 14:06:24.111 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [infacal.hadoop.env.entry.PATH,/opt/Informatica/services/shared/hadoop/cloudera_cdh5u5/scripts:/opt/Informatica//services/shared/bin:/opt/Informatica//ODBC7.1/bin:/opt/Informatica//jre/bin:/opt/Informatica//java/jre/bin:/sbin:/usr/sbin/:/bin:/usr/bin:$PATH].2016-07-12 14:06:24.111 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [infagrid.dis.hadoop.dist,../../services/shared/hadoop/cloudera_cdh5u5].2016-07-12 14:06:24.111 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [infaspark.driver.client.mode.thirdparty.jars,/export/home/dtmqa/Informatica/10.1.0/364/tomcat/bin/../../services/shared/hadoop/cloudera_cdh5u5/lib/datanucleus-api-jdo-3.2.6.jar,/export/home/dtmqa/Informatica/10.1.0/364/tomcat/bin/../../services/shared/hadoop/cloudera_cdh5u5/lib/datanucleus-core-3.2.10.jar,/export/home/dtmqa/Informatica/10.1.0/364/tomcat/bin/../../services/shared/hadoop/cloudera_cdh5u5/lib/datanucleus-rdbms-3.2.9.jar,/opt/Informatica/services/shared/hadoop/cloudera_cdh5u5/spark/lib/spark-assembly-1.5.1-hadoop2.6.0.jar].2016-07-12 14:06:24.111 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [infagrid.tasklet.dtm.buffer.size,117964800].2016-07-12 14:06:24.111 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [spark.executorEnv.JAVA_HOME,$INFA_HOME/jre].2016-07-12 14:06:24.111 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [infacal.hadoop.env.entry.INFA_HOME,/opt/Informatica/].2016-07-12 14:06:24.111 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [infagrid.temp.storage.dir,None].2016-07-12 14:06:24.111 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [spark.executor.memory,4G].2016-07-12 14:06:24.111 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [infagrid.service.log.level,INFO].2016-07-12 14:06:24.111 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [infagrid.service.port.range.high,12600].2016-07-12 14:06:24.111 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [infaspark.executor.extraJavaOptions,-Djava.security.egd=file:/dev/./urandom -XX:MaxMetaspaceSize=256M].2016-07-12 14:06:24.111 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [infah.security.auth.type,Simple].2016-07-12 14:06:24.111 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [spark.yarn.maxAppAttempts,1].2016-07-12 14:06:24.111 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [infaspark.driver.cluster.mode.extraJavaOptions,-Djava.security.egd=file:/dev/./urandom -XX:MaxMetaspaceSize=256M].2016-07-12 14:06:24.111 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [spark.driver.memory,1G].2016-07-12 14:06:24.111 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [infagrid.tasklet.dtm.buffer.block.size,6553600].2016-07-12 14:06:24.111 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [infacal.hadoop.env.entry.INFA_HADOOP_DIST_DIR,/opt/Informatica/services/shared/hadoop/cloudera_cdh5u5].2016-07-12 14:06:24.111 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [spark.sql.autoBroadcastJoinThreshold,256000000].2016-07-12 14:06:24.112 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [infagrid.def.enable.snappy.compression,None].2016-07-12 14:06:24.112 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [infagrid.dis.informatica.home,/export/home/dtmqa/Informatica/10.1.0/364].2016-07-12 14:06:24.112 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [infacal.hadoop.env.entry.INFA_MAPRED_OSGI_CONFIG,osgi.framework.activeThreadType:false&:org.osgi.framework.storage.clean:none&:eclipse.jobs.daemon:true&:infa.osgi.enable.workdir.reuse:true&:infa.osgi.parent.workdir:/tmp/infa&:infa.osgi.workdir.poolsize:30].2016-07-12 14:06:24.112 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [infagrid.grid.task.recovery.strategy,disable.partial.restart].2016-07-12 14:06:24.112 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [infaspark.submit.path,/export/home/dtmqa/Informatica/10.1.0/364/tomcat/bin/../../services/shared/hadoop/cloudera_cdh5u5/spark/bin].2016-07-12 14:06:24.112 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [infacal.hadoop.env.entry.INFA_JAVA_BIN,/opt/Informatica//jre/bin].2016-07-12 14:06:24.112 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [infacal.hadoop.env.entry.INFA_MAPRED_CLASSPATH,/opt/Informatica/services/shared/hadoop/cloudera_cdh5u5/lib/protobuf-java-2.5.0.jar:/opt/Informatica/services/shared/hadoop/cloudera_cdh5u5/lib/hbase-client-1.0.0-cdh5.5.1.jar:/opt/Informatica/services/shared/hadoop/cloudera_cdh5u5/lib/hbase-common-1.0.0-cdh5.5.1.jar:/opt/Informatica/services/shared/hadoop/cloudera_cdh5u5/lib/hive-hbase-handler-1.1.0-cdh5.5.1.jar:/opt/Informatica/services/shared/hadoop/cloudera_cdh5u5/lib/hbase-protocol-1.0.0-cdh5.5.1.jar:/opt/Informatica/services/shared/hadoop/...[Truncated]].2016-07-12 14:06:24.112 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [infacal.hadoop.env.entry.INFA_PLUGINS_HOME,/opt/Informatica//plugins].2016-07-12 14:06:24.112 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [infacal.hadoop.yarn.resource.manager.address,psrhaqadn51:8032].2016-07-12 14:06:24.112 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [infaspark.driver.client.mode.osgi.config,osgi.framework.activeThreadType:false&:org.osgi.framework.storage.clean:none&:eclipse.jobs.daemon:true&:infa.osgi.enable.workdir.reuse:true&:infa.osgi.parent.workdir:/tmp/infaSparkClientDriver/&:infa.osgi.workdir.poolsize:4].2016-07-12 14:06:24.112 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [infacal.hadoop.env.entry.IMF_CPP_RESOURCE_PATH,/opt/Informatica//services/shared/bin].2016-07-12 14:06:24.112 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [infaspark.executor.thirdparty.jars,/opt/Informatica/services/shared/hadoop/cloudera_cdh5u5/lib/datanucleus-api-jdo-3.2.6.jar,/opt/Informatica/services/shared/hadoop/cloudera_cdh5u5/lib/datanucleus-core-3.2.10.jar,/opt/Informatica/services/shared/hadoop/cloudera_cdh5u5/lib/datanucleus-rdbms-3.2.9.jar,/opt/Informatica/services/shared/hadoop/cloudera_cdh5u5/infaLib/xml-infa-parserutil.jar,/opt/Informatica/services/shared/hadoop/cloudera_cdh5u5/infaLib/json-infa-parserutil.jar,/opt/Informatica/services/shared/hadoop/cloudera_cdh5u5/i...[Truncated]].2016-07-12 14:06:24.112 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [infacal..logservice.user,dtmqa].2016-07-12 14:06:24.112 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [infagrid.orch.scheduler.oop.container.pref.memory,5120].2016-07-12 14:06:24.112 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [infagrid.orch.scheduler.oop.container.pref.vcore,4].2016-07-12 14:06:24.112 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [infacal.hadoop.env.entry.LD_LIBRARY_PATH,/opt/Informatica//services/shared/bin:/opt/Informatica//DataTransformation/bin:/opt/Informatica/services/shared/hadoop/cloudera_cdh5u5/lib/native:/opt/Informatica//ODBC7.1/lib:/opt/Informatica//jre/lib/amd64:/opt/Informatica//jre/lib/amd64/server:/opt/Informatica//java/jre/lib/amd64:/opt/Informatica//java/jre/lib/amd64/server:$LD_LIBRARY_PATH].2016-07-12 14:06:24.112 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [infagrid.dis.hadoop.dir,/export/home/dtmqa/Informatica/10.1.0/364/services/shared/hadoop].2016-07-12 14:06:24.112 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [infacal.cluster.distribution.identifier,/data/home/dtmqa/Informatica/10.1.0/364/services/shared/hadoop/cloudera_cdh5u5].2016-07-12 14:06:24.112 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [infacal.cluster.type,yarn].2016-07-12 14:06:24.112 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [spark.yarn.appMasterEnv.JAVA_HOME,$INFA_HOME/jre].2016-07-12 14:06:24.112 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [spark.sql.shuffle.partitions,100].2016-07-12 14:06:24.112 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [infacal.hadoop.logs.directory,/var/log/hadoop-yarn/apps/informatica].2016-07-12 14:06:24.112 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [infacal.hadoop.env.entry.INFA_RESOURCES,/opt/Informatica//services/shared/bin].2016-07-12 14:06:24.112 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [infagrid.blaze.console.enabled,false].2016-07-12 14:06:24.112 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [spark.serializer,org.apache.spark.serializer.KryoSerializer].2016-07-12 14:06:24.112 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [infacal.hadoop.env.entry.IFCONTENTMASTER_HOME,/opt/Informatica//DataTransformation].2016-07-12 14:06:24.112 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [infagrid.security.cadi.user,dtmqa].2016-07-12 14:06:24.112 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [infagrid.def.max.memory,4096].2016-07-12 14:06:24.112 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [infacal.hadoop.fs.default.name,hdfs://psrhaqann51.informatica.com:8020/].2016-07-12 14:06:24.112 <pool-6-thread-8> CONFIG: [task MAINSESSION_task1]: Using grid execution configuration property [spark.executor.instances,100 ].2016-07-12 14:06:24.190 <pool-6-thread-8> INFO: [task MAINSESSION_task1]: The Integration Service submitted the mapping request to grid.2016-07-12 14:06:24.190 <pool-6-thread-8> INFO: [task MAINSESSION_task1]: [GCL_1] The Integration Service is about to submit the grid task [gtid-3616-1-40834268-20] for execution.2016-07-12 14:06:24.207 <pool-6-thread-8> INFO: [task MAINSESSION_task1]: [GCL_2] The Integration Service submitted the grid task [gtid-3616-1-40834268-20] for execution.2016-07-12 14:06:24.207 <pool-6-thread-8> INFO: [task MAINSESSION_task1]: [GCL_21] The grid task [gtid-3616-1-40834268-20] is submitted to the application ID [application_1465412277317_3616].2016-07-12 14:06:24.207 <pool-6-thread-8> INFO: [task MAINSESSION_task1]: [GCL_5] Logs for the grid task [gtid-3616-1-40834268-20] appear in the following location on the Hadoop cluster: [/opt/Informatica//blazeLogs/application_1465412277317_3616/taskletlogs/gtid-3616-1-40834268-20].2016-07-12 14:06:24.207 <pool-6-thread-8> WARNING: [task MAINSESSION_task1]: [GCL_22] If local log directory for the node on the cluster does not have the correct permissions, the local logs for the Blaze engine will appear in the current working directory of the container.2016-07-12 14:06:46.152 <DTFPool-13-thread-2> WARNING: [task MAINSESSION_task1]: [GCL_10] The grid task [gtid-3616-1-40834268-20] has encountered runtime failure(s).2016-07-12 14:06:46.153 <DTFPool-13-thread-2> INFO: [task MAINSESSION_task1]: [GCL_6] The grid task [gtid-3616-1-40834268-20] has the following statistics:      \tTasklets                             : [2]      \tsuccessfully executed tasklets       : [1]      \tfailed tasklets                      : [1]      \tcancelled tasklets before execution  : [0]      \tcancelled tasklets during execution  : [0]2016-07-12 14:06:46.153 <DTFPool-13-thread-2> INFO: [task MAINSESSION_task1]: [GCL_8] The following error appears for all failed tasklets in the grid task [gtid-3616-1-40834268-20]: [The tasklet [gtid-3616-1-40834268-20_s0_t-0] failed with the following error: [WRT_8229 Database errors occurred: ORA-24816: Expanded non LONG bind data supplied after actual LONG or LOB columnDatabase driver error...Function Name : ExecuteSQL Stmt : INSERT INTO \"ADT_TGT\"(\"COL_KEY\",\"COL_BLOB\",\"COL_CLOB\",\"COL_DATE\",\"COL_NCHAR\",\"COL_NCLOB\",\"COL_NUMBER\",\"COL_NUMBER_PS\",\"COL_NUMBER_BIGINT\",\"COL_NVARCHAR2\",\"COL_RAW\",\"COL_TIMESTAMP\",\"COL_VARCHAR2\")  VALUES ( ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?) Oracle Fatal ErrorDatabase driver error...Function Name : Execute MultipleSQL Stmt : INSERT INTO \"ADT_TGT\"(\"COL_KEY\",\"COL_BLOB\",\"COL_CLOB\",\"COL_DATE\",\"COL_NCHAR\",\"COL_NCLOB\",\"COL_NUMBER\",\"COL_NUMBER_PS\",\"COL_NUMBER_BIGINT\",\"COL_NVARCHAR2\",\"COL_RAW\",\"COL_TIMESTAMP\",\"COL_VARCHAR2\")  VALUES ( ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?) Oracle Fatal Error].].2016-07-12 14:06:46.153 <DTFPool-13-thread-2> INFO: [task MAINSESSION_task1]: [GCL_15] The grid task [gtid-3616-1-40834268-20] has been restarted.2016-07-12 14:07:01.124 <DTFPool-13-thread-2> FINE: [task MAINSESSION_task1]: [GCL_18] The grid task [gtid-3616-1-40834268-20] did not generate any output.2016-07-12 14:07:01.124 <DTFPool-13-thread-2> INFO: [task MAINSESSION_task1]: [GCL_19] The grid task [gtid-3616-1-40834268-20] has the tracking URL [http://psrhaqadn51.informatica.com:9080/Blaze?tasktype=gridtask&id=gtid-3616-1-40834268-20&isParent=false].2016-07-12 14:07:01.124 <DTFPool-13-thread-2> INFO: [task MAINSESSION_task1]: [GCL_25] High availability is enabled.2016-07-12 14:07:01.124 <DTFPool-13-thread-2> INFO: [task MAINSESSION_task1]: [GCL_27] Recovery strategy is set to [FULL_RESTART].2016-07-12 14:07:01.124 <DTFPool-13-thread-2> SEVERE: [task MAINSESSION_task1]: [GCL_4] The grid task [gtid-3616-1-40834268-20] execution failed.2016-07-12 14:07:01.124 <DTFPool-13-thread-2> INFO: [task MAINSESSION_task1]: [GCL_6] The grid task [gtid-3616-1-40834268-20] has the following statistics:      \tTasklets                             : [2]      \tsuccessfully executed tasklets       : [1]      \tfailed tasklets                      : [1]      \tcancelled tasklets before execution  : [0]      \tcancelled tasklets during execution  : [0]2016-07-12 14:07:01.124 <DTFPool-13-thread-2> INFO: [task MAINSESSION_task1]: [GCL_8] The following error appears for all failed tasklets in the grid task [gtid-3616-1-40834268-20]: [The tasklet [gtid-3616-1-40834268-20_s0_t-0] failed with the following error: [WRT_8229 Database errors occurred: ORA-24816: Expanded non LONG bind data supplied after actual LONG or LOB columnDatabase driver error...Function Name : ExecuteSQL Stmt : INSERT INTO \"ADT_TGT\"(\"COL_KEY\",\"COL_BLOB\",\"COL_CLOB\",\"COL_DATE\",\"COL_NCHAR\",\"COL_NCLOB\",\"COL_NUMBER\",\"COL_NUMBER_PS\",\"COL_NUMBER_BIGINT\",\"COL_NVARCHAR2\",\"COL_RAW\",\"COL_TIMESTAMP\",\"COL_VARCHAR2\")  VALUES ( ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?) Oracle Fatal ErrorDatabase driver error...Function Name : Execute MultipleSQL Stmt : INSERT INTO \"ADT_TGT\"(\"COL_KEY\",\"COL_BLOB\",\"COL_CLOB\",\"COL_DATE\",\"COL_NCHAR\",\"COL_NCLOB\",\"COL_NUMBER\",\"COL_NUMBER_PS\",\"COL_NUMBER_BIGINT\",\"COL_NVARCHAR2\",\"COL_RAW\",\"COL_TIMESTAMP\",\"COL_VARCHAR2\")  VALUES ( ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?) Oracle Fatal Error].].2016-07-12 14:07:01.125 <pool-6-thread-8> INFO: [task MAINSESSION_task1]: Aggregated logs for the grid mapping [gtid-3616-1-40834268-20] can be found at the following location: [/var/log/hadoop-yarn/apps/informatica/application_1465412277317_3616/TaskletLogs/gtid-3616-1-40834268-20].2016-07-12 14:07:01.130 <pool-6-thread-8> INFO: [LDTM_0131] SESSION LOAD SUMMARY for grid task [MAINSESSION_task1] : =====================================================Source Load Summary.Instance Name: [Read_ALL_DATATYPES_SUCHARITHA]      Output Rows [720], Rejected Rows [0]Target Load Summary.Instance Name: [Write_ADT_TGT]      Output Rows [0], Rejected Rows [0]Instance Name: [Write_ADT_TGT]      Output Rows [0], Rejected Rows [0]=====================================================2016-07-12 14:07:01.130 <pool-6-thread-8> SEVERE: [LDTM_3506] The Integration Service failed to run the task [MAINSESSION_task1]. See the additional error messages for more information.Exception Class: [com.informatica.sdk.dtm.ExecutionException]\tException Message: [[GRIDDTM_1016] The Integration Service failed to execute grid mapping with following error [WRT_8229 Database errors occurred: ORA-24816: Expanded non LONG bind data supplied after actual LONG or LOB columnDatabase driver error...Function Name : ExecuteSQL Stmt : INSERT INTO \"ADT_TGT\"(\"COL_KEY\",\"COL_BLOB\",\"COL_CLOB\",\"COL_DATE\",\"COL_NCHAR\",\"COL_NCLOB\",\"COL_NUMBER\",\"COL_NUMBER_PS\",\"COL_NUMBER_BIGINT\",\"COL_NVARCHAR2\",\"COL_RAW\",\"COL_TIMESTAMP\",\"COL_VARCHAR2\")  VALUES ( ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?) Oracle Fatal ErrorDatabase driver error...Function Name : Execute MultipleSQL Stmt : INSERT INTO \"ADT_TGT\"(\"COL_KEY\",\"COL_BLOB\",\"COL_CLOB\",\"COL_DATE\",\"COL_NCHAR\",\"COL_NCLOB\",\"COL_NUMBER\",\"COL_NUMBER_PS\",\"COL_NUMBER_BIGINT\",\"COL_NVARCHAR2\",\"COL_RAW\",\"COL_TIMESTAMP\",\"COL_VARCHAR2\")  VALUES ( ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?) Oracle Fatal Error].].2016-07-12 14:07:01.132 <DTM-pool-2-thread-3> FINE: [LDTM_3519] Workflow Execution Clean Up Task has started2016-07-12 14:07:01.133 <DTM-pool-2-thread-3> FINE: [LDTM_0126] Command task: [CLEANUP_task3]. Command executing: [1/2]. Command string executing: [../../services/shared/hadoop/cloudera_cdh5u5/scripts/HadoopFsRmRf --hadoop.home ../../services/shared/hadoop/cloudera_cdh5u5 --hdfsUser dtmqa hdfs://psrhaqann51.informatica.com:8020//blaze/workdir/W7798867335968217259_Write_ADT_TGT_INFA456847/reject-files].2016-07-12 14:07:05.502 <DTM-pool-2-thread-3> FINE: [LDTM_0127] Command task: [CLEANUP_task3]. Command executing: [1/2]. Command execution process: [STDOUT/STDERR]. Command execution output: [Deleting hdfs://psrhaqann51.informatica.com:8020/blaze/workdir/W7798867335968217259_Write_ADT_TGT_INFA456847/reject-filesDeleting files successful.].2016-07-12 14:07:05.502 <DTM-pool-2-thread-3> FINE: [LDTM_0126] Command task: [CLEANUP_task3]. Command executing: [2/2]. Command string executing: [../../services/shared/hadoop/cloudera_cdh5u5/scripts/HadoopFsRmRf --hadoop.home ../../services/shared/hadoop/cloudera_cdh5u5 --hdfsUser dtmqa hdfs://psrhaqann51.informatica.com:8020//blaze/workdir/W7798867335968217259_Write_ADT_TGT_INFA456847/].2016-07-12 14:07:08.087 <DTM-pool-2-thread-3> FINE: [LDTM_0127] Command task: [CLEANUP_task3]. Command executing: [2/2]. Command execution process: [STDOUT/STDERR]. Command execution output: [Deleting hdfs://psrhaqann51.informatica.com:8020/blaze/workdir/W7798867335968217259_Write_ADT_TGT_INFA456847Deleting files successful.].2016-07-12 14:07:08.087 <DTM-pool-2-thread-3> INFO: [LDTM_0128] The Command task [CLEANUP_task3] has successfully completed [2/2] commands2016-07-12 14:07:08.087 <DTM-pool-2-thread-3> FINE: [LDTM_3520] Workflow Execution Clean Up Task has completed successfully2016-07-12 14:07:08.089 <DTM-pool-2-thread-3> SEVERE: [GRIDDTM_1016] The Integration Service failed to execute grid mapping with following error [WRT_8229 Database errors occurred: ORA-24816: Expanded non LONG bind data supplied after actual LONG or LOB columnDatabase driver error...Function Name : ExecuteSQL Stmt : INSERT INTO \"ADT_TGT\"(\"COL_KEY\",\"COL_BLOB\",\"COL_CLOB\",\"COL_DATE\",\"COL_NCHAR\",\"COL_NCLOB\",\"COL_NUMBER\",\"COL_NUMBER_PS\",\"COL_NUMBER_BIGINT\",\"COL_NVARCHAR2\",\"COL_RAW\",\"COL_TIMESTAMP\",\"COL_VARCHAR2\")  VALUES ( ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?) Oracle Fatal ErrorDatabase driver error...Function Name : Execute MultipleSQL Stmt : INSERT INTO \"ADT_TGT\"(\"COL_KEY\",\"COL_BLOB\",\"COL_CLOB\",\"COL_DATE\",\"COL_NCHAR\",\"COL_NCLOB\",\"COL_NUMBER\",\"COL_NUMBER_PS\",\"COL_NUMBER_BIGINT\",\"COL_NVARCHAR2\",\"COL_RAW\",\"COL_TIMESTAMP\",\"COL_VARCHAR2\")  VALUES ( ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?) Oracle Fatal Error].2016-07-12 14:07:08.089 <DTM-pool-2-thread-3> INFO: com.informatica.sdk.dtm.ExecutionException: [GRIDDTM_1016] The Integration Service failed to execute grid mapping with following error [WRT_8229 Database errors occurred: ORA-24816: Expanded non LONG bind data supplied after actual LONG or LOB columnDatabase driver error...Function Name : ExecuteSQL Stmt : INSERT INTO \"ADT_TGT\"(\"COL_KEY\",\"COL_BLOB\",\"COL_CLOB\",\"COL_DATE\",\"COL_NCHAR\",\"COL_NCLOB\",\"COL_NUMBER\",\"COL_NUMBER_PS\",\"COL_NUMBER_BIGINT\",\"COL_NVARCHAR2\",\"COL_RAW\",\"COL_TIMESTAMP\",\"COL_VARCHAR2\")  VALUES ( ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?) Oracle Fatal ErrorDatabase driver error...Function Name : Execute MultipleSQL Stmt : INSERT INTO \"ADT_TGT\"(\"COL_KEY\",\"COL_BLOB\",\"COL_CLOB\",\"COL_DATE\",\"COL_NCHAR\",\"COL_NCLOB\",\"COL_NUMBER\",\"COL_NUMBER_PS\",\"COL_NUMBER_BIGINT\",\"COL_NVARCHAR2\",\"COL_RAW\",\"COL_TIMESTAMP\",\"COL_VARCHAR2\")  VALUES ( ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?) Oracle Fatal Error].\tat com.informatica.platform.dtm.executor.grid.GridExecutor.run(GridExecutor.java:340)\tat com.informatica.platform.dtm.executor.grid.task.impl.GridMappingTaskHandlerImpl.executeMainScript(GridMappingTaskHandlerImpl.java:87)\tat com.informatica.platform.ldtm.executor.common.workflow.taskhandler.impl.BaseTaskHandlerImpl.run(BaseTaskHandlerImpl.java:129)\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\tat java.lang.Thread.run(Thread.java:745)2016-07-12 14:07:08.089 <DTM-pool-2-thread-3> SEVERE: [LDTM_3503] The Integration Service failed to execute the mapping.2016-07-12 14:07:08.089 <DTM-pool-2-thread-3> INFO: [LDTM_0075] Total time to perform the LDTM operation: 45,954 ms","startTime":"2016-07-12 14:06:08.404","endTime":"2016-07-12 14:07:08.089","sessionLogErrors":null,"clusterDetails":null,"failedTasklets":[{"taskletID":"gtid-3616-1-40834268-20_s0_t-0","nodeName":"psrhaqadn51.informatica.com","taskletLog":null,"containerManagerLog":null,"taskletErrors":"SEVERE: [WRT_8229] Database errors occurred:ORA-24816: Expanded non LONG bind data supplied after actual LONG or LOB column","containermanagerErrors":null}],"blazeMonitorURL":"http://psrhaqadn51.informatica.com:9080/Blaze?tasktype=gridtask&id=gtid-3616-1-40834268-20&isParent=false]",
"totalTasklets": 8, "numFailedTasklets": 1,  "mappingSuccessful":false}